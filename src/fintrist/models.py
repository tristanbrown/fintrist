"""
The engine that applies analyses to data and generates alerts.
"""
import logging
import pickle
import inspect
import re
import datetime as dt
from dateutil.tz import tzlocal

from mongoengine.document import Document, EmbeddedDocument
from mongoengine.fields import (
    DateTimeField, DictField, EmbeddedDocumentField,
    EmbeddedDocumentListField, IntField, FileField,
    ListField, MapField, ReferenceField, StringField,
)
from mongoengine import signals
from apscheduler.jobstores.base import JobLookupError
from bson.dbref import DBRef
# import dask.multiprocessing as daskmp
import dask.threaded as daskth
import numpy as np
import pandas as pd

from fintrist import util
from fintrist.settings import Config
from fintrist.scheduling import scheduler
from fintrist.notify import Notification
import fintrist_ds

__all__ = ('BaseStudy', 'Study', 'Backtest', 'Process', 'Trigger')

logger = logging.getLogger(__name__)

class Alerts(EmbeddedDocument):
    """Alerts generated by a Study."""
    timestamp = DateTimeField(default=dt.datetime.now(tzlocal()))
    active = ListField(StringField(max_length=120))

    # Meta
    schema_version = IntField(default=1)
    meta = {'strict': False}

class AlertsLog(EmbeddedDocument):
    """Log of Alerts."""
    log = EmbeddedDocumentListField('Alerts')
    count = IntField(default=100)

    # Meta
    schema_version = IntField(default=1)
    meta = {'strict': False}

    def trim(self):
        """Trim the log to the specified size."""
        if len(self.log) > self.count:
            self.log = self.log[:self.count]

    def record_alerts(self, alerts, timestamp):
        """Take in a new list of alerts.

        alerts (list): [str]
        """
        newalerts = Alerts(timestamp=timestamp, active=alerts)
        self.log = [newalerts] + self.log

    def get_alerts(self, idx):
        """Get the alerts at the given lookback index."""
        try:
            return set(self.log[idx].active)
        except IndexError:
            return set()

    @property
    def newest(self):
        """Most recent alerts."""
        return self.get_alerts(0)

    @property
    def newactive(self):
        """Newly active alerts."""
        return self.get_alerts(0) - self.get_alerts(1)

    @property
    def newinactive(self):
        """Newly inactive alerts."""
        return self.get_alerts(1) - self.get_alerts(0)

    def clear(self):
        """Delete all alerts."""
        self.log = []

class Trigger(EmbeddedDocument):
    """A rule determining how an action is triggered."""
    alert_types = ('active', 'inactive', 'all')
    match_if = ('in', 'is',)
    action_choices = ('log', 'printhead', 'email', 'sms', 'buy', 'sell')
    on = StringField(default='active', choices=alert_types)
    condition = StringField(default='in', choices=match_if)
    # TODO: Change matchtext to populate choices based on the analysis
    matchtext = StringField(max_length=120)
    actions = ListField(StringField(choices=action_choices))

    # Meta
    schema_version = IntField(default=1)
    meta = {'strict': False}

    def __str__(self):
        return f"{self.matchtext} {self.condition} {self.on}"

    def check_fire(self, study):
        """Check if the trigger should be fired, and then run actions."""
        triggered = self.check_conds(study.alertslog)
        if triggered:
            self.fire(study=study, alerts=triggered)

    def get_actions(self, alertslog):
        """Return any actions that should be triggered."""
        triggered = self.check_conds(alertslog)
        if triggered:
            return self.actions
        else:
            return []

    def check_conds(self, alertslog):
        """Check if the conditions for triggering have been met by the alert."""
        if self.on == 'active':
            alerts = alertslog.newactive
        elif self.on == 'inactive':
            alerts = alertslog.newinactive
        elif self.on == 'all':
            alerts = alertslog.newest
        triggered = []
        for alert in alerts:
            if self.condition == 'in' and self.matchtext in alert:
                triggered.append(alert)
            elif self.condition == 'is' and self.matchtext == alert:
                triggered.append(alert)
        return triggered

    def fire(self, **kwargs):
        """Trigger the specified actions."""
        Notification(self.actions, **kwargs)

@util.handler(signals.pre_delete)
def clean_files(sender, document):  #pylint: disable=unused-argument
    """Signal deleted Studies to remove data files."""
    document.remove_files()

@clean_files.apply
class BaseStudy(Document):
    """Contains data process results."""
    # ID
    name = StringField(max_length=120, required=True)

    # Data Inputs
    parents = MapField(ReferenceField('BaseStudy'))  # Precursor data used by the Analysis
    params = DictField()  # Processing parameters.

    # Data Outputs
    file = FileField()
    newfile = FileField()
    timestamp = DateTimeField(default=dt.datetime.now(tzlocal()))
    valid_age = IntField(default=0)  # Zero means always valid

    # Meta
    schema_version = IntField(default=1)
    meta = {
        'strict': False,
        'collection': 'study',
        'allow_inheritance': True,
        }

    # pylint: disable=no-member
    def clean(self):
        """Clean attributes."""
        # Parents
        for key, parent in self.parents.items():
            if isinstance(parent, DBRef):
                del self.parents[key]
        self.subclean()

    def subclean(self):
        """Cleaning operations for subclasses."""
        pass

    ## Methods defining the Study ##

    def rename(self, newname):
        """Rename the Study."""
        self.name = newname
        self.save()
        self.reload()
        if self.active:
            scheduler.modify_job(str(self.id), name=self.name)

    ## Methods related to scheduling runs ##

    @property
    def valid(self):
        """Check if the Study data is still valid."""
        # Check the age of the data
        if self.valid_age == 0:
            current = True
        else:
            current = dt.datetime.utcnow() - self.timestamp < dt.timedelta(seconds=self.valid_age)
        # Check if the parents are valid too
        if current:
            for parent in self.parents.values():
                if not parent.valid:
                    current = False
                    break
        return current

    @property
    def dependencies(self):
        """Create a dictionary of dependencies."""
        deps = {str(self.id): [str(parent.id) for parent in self.parents.values()]}
        for parent in self.parents.values():
            deps.update(parent.dependencies)
        return deps

    @property
    def active(self):
        """Boolean value of whether the Study is active in the scheduler."""
        return False

    def run_if(self, dummy=None):
        """Run the Study if it's no longer valid."""
        if not self.valid:
            self.run()

    def run(self, dummy=None):
        """Run the Study process on the inputs and return any alerts."""
        raise Exception("Cannot run from BaseStudy objects.")

    ## Methods for handling inputs ##

    def add_parents(self, newparents):
        """Add all of the parents in the given dict of ids."""
        parent_objects = {key: BaseStudy.objects(id=val).get() for key, val in newparents.items()}
        self.parents.update(parent_objects)
        self.save()

    def add_params(self, newparams):
        """Add all of the params in the given dict."""
        self.params.update(newparams)
        self.save()

    def remove_inputs(self, inputs):
        """Remove all of the inputs in the given iterable of names."""
        for key in inputs:
            self.parents.pop(key, None)
            self.params.pop(key, None)
        self.save()

    ## Methods for handling the saved data ##

    @property
    def data(self):
        """Preprocess the data field to return the data in a usable format."""
        self.transfer_file()
        file_obj = self.file.get()
        try:
            result = file_obj.read()
            file_obj.seek(0)
            return pickle.loads(result)
        except:
            return None

    @data.setter
    def data(self, newdata):
        """Process the data for storage."""
        if newdata is None:
            self.remove_files()
        else:
            if not self.file:
                self.write_to(self.file, newdata)
            else:
                self.write_to(self.newfile, newdata)
                self.transfer_file()

    def write_to(self, field, newdata):
        """Write data to a FileField."""
        field.new_file()
        field.write(pickle.dumps(newdata))
        field.close()
        self.save()

    def transfer_file(self):
        """Transfer the data from newfile to file."""
        if self.newfile:
            newfile = self.newfile.read()
            self.file.replace(newfile)
            self.save()
            self.newfile.delete()
            self.save()

    def remove_files(self):
        """Remove the data."""
        self.file.delete()
        self.newfile.delete()
        self.save(validate=False)

@clean_files.apply
class Study(BaseStudy):
    """Contains data process results."""
    # Defining the analysis that generated the data
    process = ReferenceField('Process', required=True)

    # Alerts
    alertslog = EmbeddedDocumentField('AlertsLog', default=AlertsLog())
    triggers = MapField(EmbeddedDocumentField('Trigger'))

    # pylint: disable=no-member
    # pylint: disable=not-a-mapping
    # pylint: disable=unsupported-delete-operation
    # pylint: disable=unsupported-assignment-operation
    def __repr__(self):
        return f"Study: {self.name}"

    def subclean(self):
        """Clean attributes."""
        # Alertslog
        self.alertslog.trim()

    ## Methods defining the Study ##

    def set_process(self, name):
        """Set the Study's Process based on a name."""
        self.process = Process.objects(name=name).get()
        self.save()

    def update_valid_age(self, new_age):
        """Update the valid age for the data."""
        self.valid_age = new_age
        self.save()
        self.reload()
        if self.active:
            scheduler.reschedule_job(str(self.id), trigger='interval', seconds=self.valid_age)

    ## Methods related to scheduling runs ##

    @property
    def active(self):
        """Boolean value of whether the Study is active in the scheduler."""
        return bool(scheduler.get_job(str(self.id)))

    def activate(self):
        """Periodically run the Study."""
        scheduler.add_job(
            self.schedule_study,
            args=[str(self.id)],
            trigger='interval',
            seconds=self.valid_age,
            id=str(self.id),
            name=self.name,
            replace_existing=True,
            next_run_time=dt.datetime.now()
        )

    def deactivate(self):
        """Stop the Study from running periodically."""
        try:
            scheduler.remove_job(str(self.id))
            scheduler.remove_job(str(self.id) + '_waiting')
        except JobLookupError:
            print("Job not found")

    def run_study_once(self, force=False):
        """Submit a job to run the whole Study once."""
        scheduler.add_job(
            self.schedule_study,
            args=[str(self.id), force],
            id=str(self.id) + '_once',
            name=self.name + ' once',
            replace_existing=False,
        )

    @classmethod
    def schedule_study(cls, study_id, force=False):
        """Static wrapper for `schedule`."""
        this_study = cls.objects(id=study_id).get()
        this_study.schedule(force)

    def schedule(self, force=False):
        """Schedule the Study to run when all of its inputs are valid."""
        daskth.get(self.get_dag(force), str(self.id), num_workers=Config.NUM_WORKERS)

    def get_dag(self, force=False):
        """Get the directed acyclic graph for this Study."""
        dag = {}
        for key, deps in self.dependencies.items():
            study_obj = BaseStudy.objects(id=key).get()
            if force or key == str(self.id):
                run = study_obj.run
            else:
                run = study_obj.run_if
            dag[key] = (run, deps)
        return dag

    def run(self, dummy=None):
        """Run the Study process on the inputs and return any alerts."""
        function = self.process.function
        parent_data = {name: study.data for name, study in self.parents.items()}
        self.data, newalerts = function(**parent_data, **self.params)
        self.timestamp = dt.datetime.now(tzlocal())
        self.alertslog.record_alerts(newalerts, self.timestamp)
        self.save()
        self.fire_alerts()

    ## Methods for handling inputs ##

    @property
    def all_parents(self):
        """Full dict of parent kwargs, even if not set yet."""
        return {key: self.parents.get(key) for key in self.process.parents}

    @property
    def all_params(self):
        """Full dict of param kwargs, even if not set yet."""
        return {key: self.params.get(key) for key in self.process.params}

    ## Methods for handling alerts ##

    @property
    def alerts(self):
        """Most recent alerts."""
        return self.alertslog.newest

    def clear_log(self):
        """Remove log entries."""
        self.alertslog.clear()
        self.save()

    def fire_alerts(self):
        """Fire alert triggers based on newly active and inactive alerts."""
        for trigger in self.triggers.values():
            trigger.check_fire(self)

    def check_actions(self, alertslog):
        """Check the triggered actions."""
        actions = set()
        for trigger in self.triggers.values():
            actions.update(trigger.get_actions(alertslog))
        return actions

    def get_trigger(self, trig_id):
        """Return the desired trigger."""
        return self.triggers.get(trig_id)

    def add_trigger(self, matchtext, **kwargs):
        """Add a Trigger to the Study, or update a matching one."""
        new = Trigger(matchtext=matchtext, **kwargs)
        self.triggers[str(new)] = new
        self.save()

    def del_trigger(self, trig_id):
        """Delete the specified trigger."""
        try:
            del self.triggers[trig_id]
            self.save()
        except KeyError:
            print(f"Trigger '{trig_id}' not found.")

@clean_files.apply
class Backtest(BaseStudy):
    """Contains backtesting results.

    days: Length of the backtesting interval.
    end: Last date of the backtesting interval.

    super.parents (dict):
        model: Study containing the analysis to backtest
        prices: Study containing historical price data

    run: Run the analysis on each day of the interval, recording the action
        signals that are triggered.

    trade: Simulates a trading portfolio based on the action signals stored
        after Backtest.run.
    """
    days = IntField(default=365)
    end = DateTimeField(default=dt.datetime.now(tzlocal()))

    # pylint: disable=unsubscriptable-object
    def __repr__(self):
        return f"Backtest: {self.name}"

    @property
    def start(self):
        """The first date of the interval"""
        return self.end - dt.timedelta(days=self.days)

    def run(self, dummy=None):
        """Backtest the model Study on the interval and record actions."""
        model = self.parents['model']
        prices = self.parents['price']
        function = model.process.function
        parent_data = {name: study.data for name, study in model.parents.items()}

        # Run on each day in the interval
        simulated = []
        alertslog = AlertsLog()
        for view_date in model.data[self.start:self.end].index:
            trunc_data = {name: data[:view_date] for name, data in parent_data.items()}
            _, newalerts = function(**trunc_data, **model.params)
            alertslog.record_alerts(newalerts, view_date)
            actions = model.check_actions(alertslog)
            simulated.append((view_date, actions))

        # Save the data
        simdata = pd.DataFrame(simulated, columns=['date', 'signals']).set_index('date')
        pricedata = prices.data
        simdata['price'] = (pricedata['high'] + pricedata['low'])/2
        self.data = simdata
        self.timestamp = dt.datetime.now(tzlocal())
        self.save()

class Process(Document):
    """Handles for choosing the appropriate data-processing functions.
    Parent arguments and parameters are parsed from the function docstring.
    """
    # Identity
    name = StringField(max_length=120, required=True, primary_key=True)

    # Args
    parents = ListField(StringField())
    params = ListField(StringField())

    # Meta
    schema_version = IntField(default=1)

    def clean(self):
        """Ensure the function is encoded properly."""
        # Set the args
        self.parents, self.params = self.get_proc_params(self.function)

    @property
    def function(self):
        """Get the function corresponding to the Process name."""
        return fintrist_ds.CATALOG[self.name]

    def get_proc_params(self, func):
        """Return the names for the parent data and parameter arguments."""
        parents = []
        params = []
        docstr = inspect.getdoc(func)
        for line in docstr.splitlines():
            words = re.findall(r"[\w']+", line)
            if line.startswith('::parents::'):
                parents.extend(words[1:])
            elif line.startswith('::params::'):
                params.extend(words[1:])
        return parents, params
